{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this section, we'll be doing four things.\n",
    "\n",
    "- Cleaning : we'll fill in missing values.\n",
    "\n",
    "- Removing : we'll removing the less relevant variables that doesn't improve predictions, as \"Ticket\" and \"Cabin\", because they contains many null values both in training and test datatest. Therefore, \"PassengerId\" may be also dropped from training dataset as it does not contribute to survival\n",
    "\n",
    "- Data Binning : we'll transform  categorical features into numerical as \"Sex\", \"Embarked\"\n",
    "\n",
    "- Creating New Varibles: we'll create new variable called \"FamilySize\" based on \"Parch\" feature and \"SibSp\" feature.\n",
    "  we'll create \"IsAlone\" feature to check if a person traveling alone is more likely to survived or died\n",
    "  We may want to engineer the Name feature to extract Title as a new feature, to determine if it played a role in       survival."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Checking for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cabin</th>\n",
       "      <td>687</td>\n",
       "      <td>77.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>177</td>\n",
       "      <td>19.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked</th>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticket</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Total     %\n",
       "Cabin       687  77.1\n",
       "Age         177  19.9\n",
       "Embarked      2   0.2\n",
       "Fare          0   0.0\n",
       "Ticket        0   0.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's take more detaild look of what data is actually missing \n",
    "total = train.isnull().sum().sort_values(ascending=False)\n",
    "percent_1 = train.isnull().sum()/train.isnull().count()*100\n",
    "percent_2 = (round(percent_1, 1)).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent_2], axis=1, keys=['Total', '%'])\n",
    "missing_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A critical part of the success of a Machine Learning Project is Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    False\n",
       "Survived       False\n",
       "Pclass         False\n",
       "Name           False\n",
       "Sex            False\n",
       "Age             True\n",
       "SibSp          False\n",
       "Parch          False\n",
       "Ticket         False\n",
       "Fare           False\n",
       "Cabin           True\n",
       "Embarked        True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    False\n",
       "Pclass         False\n",
       "Name           False\n",
       "Sex            False\n",
       "Age             True\n",
       "SibSp          False\n",
       "Parch          False\n",
       "Ticket         False\n",
       "Fare            True\n",
       "Cabin           True\n",
       "Embarked       False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Filling missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing Age\n",
    "\n",
    "\n",
    "train[\"Age\"] = train[\"Age\"]. fillna(train[\"Age\"].mean())\n",
    "\n",
    "test[\"Age\"]  = test[\"Age\"] . fillna(test[\"Age\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing Fare\n",
    "\n",
    "test[\"Fare\"] = test [\"Fare\"]. fillna(test[\"Fare\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Bining Categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing Sex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Before we fit the data into a machine learning algorithm, there is a step very crucial is that we make sure to encode categorical variables correctly\n",
    "\n",
    "We will change Sex to binary, as either 1 for female or 0 for male. We do the same for Embarked. We do this same process on both the training and testing set to prepare our data for Machine Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train[\"Sex\"] == \"male\" , \"Sex\"] = 0\n",
    "train.loc[train[\"Sex\"] == \"female\",\"Sex\"] = 1\n",
    "\n",
    "\n",
    "\n",
    "test.loc[test[\"Sex\"] == \"male\", \"Sex\"] = 0\n",
    "test.loc[test[\"Sex\"] == \"female\", \"Sex\"] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing Embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train[\"Embarked\"] == \"S\", \"Embarked\"] = 0\n",
    "train.loc[train[\"Embarked\"] == \"C\", \"Embarked\"] = 1\n",
    "train.loc[train[\"Embarked\"] == \"Q\", \"Embarked\"] = 2\n",
    "\n",
    "\n",
    "test.loc[test[\"Embarked\"]  == \"S\", \"Embarked\"] = 0\n",
    "test.loc[test[\"Embarked\"]  == \"C\", \"Embarked\"] = 1\n",
    "test.loc[test[\"Embarked\"]  == \"Q\", \"Embarked\"] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"Embarked\"].fillna(\"S\", inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Creating New Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, introducing new features as Family size (to join these Parch and SibSp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"FamSize\"] = train[\"SibSp\"] + train[\"Parch\"] + 1\n",
    "test[\"FamSize\"]  =  test[\"SibSp\"] + test[\"Parch\"]  + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next option is to cerate IsAlone feature to check wheter a person traveling alolne is more likely to survived or died"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"IsAlone\"] = train.FamSize.apply(lambda x: 1 if x == 1 else 0)\n",
    "test[\"IsAlone\"]  = test.FamSize.apply( lambda x: 1 if x == 1 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction the passengers titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have a quick look in the names of the passengers we will notice that each name has a title in it, so it can be a useful information for our analyze. Therefore we can extract this title from the name of each passenger and then encode it like we did for Sex and Embarked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in train[\"Name\"]:\n",
    "    train[\"Title\"] = train[\"Name\"].str.extract(\"([A-Za-z]+)\\.\",expand=True)\n",
    "    \n",
    "for name in test[\"Name\"]:\n",
    "    test[\"Title\"] = test[\"Name\"].str.extract(\"([A-Za-z]+)\\.\",expand=True)\n",
    "    \n",
    "title_replacements = {\"Mlle\": \"Other\", \"Major\": \"Other\", \"Col\": \"Other\", \"Sir\": \"Other\", \"Don\": \"Other\", \"Mme\": \"Other\",\n",
    "          \"Jonkheer\": \"Other\", \"Lady\": \"Other\", \"Capt\": \"Other\", \"Countess\": \"Other\", \"Ms\": \"Other\", \"Dona\": \"Other\", \"Rev\": \"Other\", \"Dr\": \"Other\"}\n",
    "\n",
    "train.replace({\"Title\": title_replacements}, inplace=True)\n",
    "test.replace({\"Title\": title_replacements}, inplace=True)\n",
    "\n",
    "train.loc[train[\"Title\"] == \"Miss\", \"Title\"] = 0\n",
    "train.loc[train[\"Title\"] == \"Mr\", \"Title\"] = 1\n",
    "train.loc[train[\"Title\"] == \"Mrs\", \"Title\"] = 2\n",
    "train.loc[train[\"Title\"] == \"Master\", \"Title\"] = 3\n",
    "train.loc[train[\"Title\"] == \"Other\", \"Title\"] = 4\n",
    "\n",
    "test.loc[test[\"Title\"] == \"Miss\", \"Title\"] = 0\n",
    "test.loc[test[\"Title\"] == \"Mr\", \"Title\"] = 1\n",
    "test.loc[test[\"Title\"] == \"Mrs\", \"Title\"] = 2\n",
    "test.loc[test[\"Title\"] == \"Master\", \"Title\"] = 3\n",
    "test.loc[test[\"Title\"] == \"Other\", \"Title\"] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3, 4}\n"
     ]
    }
   ],
   "source": [
    "print(set(train[\"Title\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Age'] = train['Age'].astype(int)\n",
    "train.loc[ train['Age'] <= 11, 'Age'] = 0\n",
    "train.loc[(train['Age'] > 11) & (train['Age'] <= 18), 'Age'] = 1\n",
    "train.loc[(train['Age'] > 18) & (train['Age'] <= 22), 'Age'] = 2\n",
    "train.loc[(train['Age'] > 22) & (train['Age'] <= 27), 'Age'] = 3\n",
    "train.loc[(train['Age'] > 27) & (train['Age'] <= 33), 'Age'] = 4\n",
    "train.loc[(train['Age'] > 33) & (train['Age'] <= 40), 'Age'] = 5\n",
    "train.loc[(train['Age'] > 40) & (train['Age'] <= 66), 'Age'] = 6\n",
    "train.loc[ train['Age'] > 66, 'Age'] = 6\n",
    "\n",
    "# let's see how it's distributed train_df['Age'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Age'] = test['Age'].astype(int)\n",
    "test.loc[test['Age']<= 11, 'Age'] =0\n",
    "test.loc[(test['Age'] > 11)& (test['Age'] <= 18), 'Age'] = 1\n",
    "test.loc[(test['Age'] > 18) & (test['Age'] <= 22), 'Age'] = 2\n",
    "test.loc[(test['Age'] > 22) & (test['Age'] <= 27), 'Age'] = 3\n",
    "test.loc[(test['Age'] > 27) & (test['Age'] <= 33), 'Age'] = 4\n",
    "test.loc[(test['Age'] > 33) & (test['Age'] <= 40), 'Age'] = 5\n",
    "test.loc[(test['Age'] > 40) & (test['Age'] <= 66), 'Age'] = 6\n",
    "test.loc[ test['Age'] > 66, 'Age'] = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Removing irrelevant variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the next step is dropping the less relevant features beacuse, The problem with less important features is that they create more noice and actually take over the importance of real features like Sex and Pclass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_drop = ['Ticket', 'SibSp', 'Parch', \"Name\", \"Cabin\", \"Fare\"]\n",
    "train = train.drop(features_drop, axis=1)\n",
    "test = test.drop(features_drop, axis=1)\n",
    "train = train.drop(['PassengerId'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Creating dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.get_dummies(train, columns=['Pclass','Sex','Embarked','Title'], \n",
    "                       drop_first=False)\n",
    "test = pd.get_dummies(test, columns=['Pclass','Sex','Embarked','Title'],\n",
    "                      drop_first=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
